From a42cd0d21dc363750d34b2d4c02cf1406aa7fad9 Mon Sep 17 00:00:00 2001
From: Eli Collins <eli@cloudera.com>
Date: Mon, 11 Jun 2012 22:32:46 -0700
Subject: [PATCH 1188/1344] HDFS-1487. FSDirectory.removeBlock() should update diskspace count of the block owner node.

Cached directory size in INodeDirectory can get permantently out of sync
with computed size, causing quota issues. This is also tracked by
HDFS-3061.

Reason: Bug fix
Author: Zhong Wang
Ref: CDH-5659
---
 .../hadoop/hdfs/server/namenode/FSDirectory.java   |    5 +++
 .../org/apache/hadoop/hdfs/TestAbandonBlock.java   |   37 ++++++++++++++++++++
 2 files changed, 42 insertions(+), 0 deletions(-)

diff --git a/src/hdfs/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java b/src/hdfs/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
index 74c13b6..24891f4 100644
--- a/src/hdfs/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
+++ b/src/hdfs/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
@@ -351,7 +351,12 @@ class FSDirectory implements FSConstants, Closeable {
       NameNode.stateChangeLog.debug("DIR* FSDirectory.addFile: "
                                     +path+" with "+block
                                     +" block is added to the file system");
+      // update space consumed
+      INode[] pathINodes = getExistingPathINodes(path);
+      updateCount(pathINodes, pathINodes.length-1, 0,
+          -fileNode.getPreferredBlockSize()*fileNode.getReplication(), true);
     }
+
     return true;
   }
 
diff --git a/src/test/org/apache/hadoop/hdfs/TestAbandonBlock.java b/src/test/org/apache/hadoop/hdfs/TestAbandonBlock.java
index 24b8ab1..4c3e0fe 100644
--- a/src/test/org/apache/hadoop/hdfs/TestAbandonBlock.java
+++ b/src/test/org/apache/hadoop/hdfs/TestAbandonBlock.java
@@ -23,11 +23,15 @@ import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.*;
+import org.apache.hadoop.hdfs.protocol.FSConstants;
 import org.apache.hadoop.hdfs.protocol.LocatedBlock;
 import org.apache.hadoop.hdfs.protocol.LocatedBlocks;
+import org.apache.hadoop.hdfs.protocol.QuotaExceededException;
 import org.apache.hadoop.hdfs.server.namenode.NameNode;
 import org.apache.hadoop.util.StringUtils;
 
+import static org.junit.Assert.*;
+
 public class TestAbandonBlock extends junit.framework.TestCase {
   public static final Log LOG = LogFactory.getLog(TestAbandonBlock.class);
   
@@ -68,4 +72,37 @@ public class TestAbandonBlock extends junit.framework.TestCase {
       try{cluster.shutdown();} catch(Exception e) {}
     }
   }
+
+  /** Make sure that the quota is decremented correctly when a block is abandoned */
+  public void testQuotaUpdatedWhenBlockAbandoned() throws IOException {
+    MiniDFSCluster cluster = new MiniDFSCluster(CONF, 2, true, null);
+    FileSystem fs = cluster.getFileSystem();
+    DistributedFileSystem dfs = (DistributedFileSystem)fs;
+
+    try {
+      // Setting diskspace quota to 3MB
+      dfs.setQuota(new Path("/"), FSConstants.QUOTA_DONT_SET, 3 * 1024 * 1024);
+
+      // Start writing a file with 2 replicas to ensure each datanode has one.
+      // Block Size is 1MB.
+      String src = FILE_NAME_PREFIX + "test_quota1";
+      FSDataOutputStream fout = fs.create(new Path(src), true, 4096, (short)2, 1024 * 1024);
+      for (int i = 0; i < 1024; i++) {
+        fout.writeByte(123);
+      }
+
+      // Shutdown one datanode, causing the block abandonment.
+      cluster.getDataNodes().get(0).shutdown();
+
+      // Close the file, new block will be allocated with 2MB pending size.
+      try {
+        fout.close();
+      } catch (QuotaExceededException e) {
+        fail("Unexpected quota exception when closing fout");
+      }
+    } finally {
+      try{fs.close();} catch(Exception e) {}
+      try{cluster.shutdown();} catch(Exception e) {}
+    }
+  }
 }
-- 
1.7.0.4

