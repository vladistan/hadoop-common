From 78f50702f060038e26296737a7fc43553a45d864 Mon Sep 17 00:00:00 2001
From: Tsz-wo Sze <szetszwo@apache.org>
Date: Fri, 14 Oct 2011 23:27:31 +0000
Subject: [PATCH 1246/1344] HDFS-2439. Fix NullPointerException in webhdfs when opening a non-existing file or creating a file without specifying the replication parameter.

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.20-security@1183556 13f79535-47bb-0310-9956-ffa450edef68
(cherry picked from commit e7e3839673c6b3af7fa6a5ad198e6c7708341422)

Author: Tsz-wo Sze
Ref: CDH-4806
---
 .../apache/hadoop/hdfs/ByteRangeInputStream.java   |    3 +++
 .../web/resources/DatanodeWebHdfsMethods.java      |    2 +-
 .../web/resources/NamenodeWebHdfsMethods.java      |    7 ++++++-
 .../hdfs/web/resources/ReplicationParam.java       |   11 +++++++++++
 .../hdfs/web/TestWebHdfsFileSystemContract.java    |   13 +++++++++++++
 5 files changed, 34 insertions(+), 2 deletions(-)

diff --git a/src/hdfs/org/apache/hadoop/hdfs/ByteRangeInputStream.java b/src/hdfs/org/apache/hadoop/hdfs/ByteRangeInputStream.java
index 945f4ac..e2e8bf3 100644
--- a/src/hdfs/org/apache/hadoop/hdfs/ByteRangeInputStream.java
+++ b/src/hdfs/org/apache/hadoop/hdfs/ByteRangeInputStream.java
@@ -18,6 +18,7 @@
 
 package org.apache.hadoop.hdfs;
 
+import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.io.InputStream;
 import java.net.HttpURLConnection;
@@ -107,6 +108,8 @@ public class ByteRangeInputStream extends FSInputStream {
           HftpFileSystem.LOG.debug("filelength = " + filelength);
         }
         in = connection.getInputStream();
+      } catch (FileNotFoundException fnfe) {
+        throw fnfe;
       } catch (IOException ioe) {
         HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);
       }
diff --git a/src/hdfs/org/apache/hadoop/hdfs/server/datanode/web/resources/DatanodeWebHdfsMethods.java b/src/hdfs/org/apache/hadoop/hdfs/server/datanode/web/resources/DatanodeWebHdfsMethods.java
index c12edcb..26add6e 100644
--- a/src/hdfs/org/apache/hadoop/hdfs/server/datanode/web/resources/DatanodeWebHdfsMethods.java
+++ b/src/hdfs/org/apache/hadoop/hdfs/server/datanode/web/resources/DatanodeWebHdfsMethods.java
@@ -126,7 +126,7 @@ public class DatanodeWebHdfsMethods {
       final int b = bufferSize.getValue(conf);
       final FSDataOutputStream out = new FSDataOutputStream(dfsclient.create(
           fullpath, permission.getFsPermission(), overwrite.getValue(),
-          replication.getValue(), blockSize.getValue(conf), null, b), null);
+          replication.getValue(conf), blockSize.getValue(conf), null, b), null);
       try {
         IOUtils.copyBytes(in, out, b);
       } finally {
diff --git a/src/hdfs/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java b/src/hdfs/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java
index dde847c..7cbe1e0 100644
--- a/src/hdfs/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java
+++ b/src/hdfs/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java
@@ -45,6 +45,7 @@ import javax.ws.rs.core.StreamingOutput;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.ContentSummary;
 import org.apache.hadoop.hdfs.protocol.DatanodeInfo;
 import org.apache.hadoop.hdfs.protocol.DirectoryListing;
@@ -112,6 +113,9 @@ public class NamenodeWebHdfsMethods {
         || op == GetOpParam.Op.GETFILECHECKSUM
         || op == PostOpParam.Op.APPEND) {
       final HdfsFileStatus status = namenode.getFileInfo(path);
+      if (status == null) {
+        throw new FileNotFoundException("File " + path + " not found.");
+      }
       final long len = status.getLen();
       if (op == GetOpParam.Op.OPEN && (openOffset < 0L || openOffset >= len)) {
         throw new IOException("Offset=" + openOffset + " out of the range [0, "
@@ -227,6 +231,7 @@ public class NamenodeWebHdfsMethods {
         try {
 
     final String fullpath = path.getAbsolutePath();
+    final Configuration conf = (Configuration)context.getAttribute(JspHelper.CURRENT_CONF);
     final NameNode namenode = (NameNode)context.getAttribute("name.node");
 
     switch(op.getValue()) {
@@ -251,7 +256,7 @@ public class NamenodeWebHdfsMethods {
     }
     case SETREPLICATION:
     {
-      final boolean b = namenode.setReplication(fullpath, replication.getValue());
+      final boolean b = namenode.setReplication(fullpath, replication.getValue(conf));
       final String js = JsonUtil.toJsonString("boolean", b);
       return Response.ok(js).type(MediaType.APPLICATION_JSON).build();
     }
diff --git a/src/hdfs/org/apache/hadoop/hdfs/web/resources/ReplicationParam.java b/src/hdfs/org/apache/hadoop/hdfs/web/resources/ReplicationParam.java
index e13aec8..1eee7ee 100644
--- a/src/hdfs/org/apache/hadoop/hdfs/web/resources/ReplicationParam.java
+++ b/src/hdfs/org/apache/hadoop/hdfs/web/resources/ReplicationParam.java
@@ -17,6 +17,11 @@
  */
 package org.apache.hadoop.hdfs.web.resources;
 
+import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_REPLICATION_DEFAULT;
+import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_REPLICATION_KEY;
+
+import org.apache.hadoop.conf.Configuration;
+
 /** Replication parameter. */
 public class ReplicationParam extends ShortParam {
   /** Parameter name. */
@@ -46,4 +51,10 @@ public class ReplicationParam extends ShortParam {
   public String getName() {
     return NAME;
   }
+
+  /** @return the value or, if it is null, return the default from conf. */
+  public short getValue(final Configuration conf) {
+    return getValue() != null? getValue()
+        : (short)conf.getInt(DFS_REPLICATION_KEY, DFS_REPLICATION_DEFAULT);
+  }
 }
\ No newline at end of file
diff --git a/src/test/org/apache/hadoop/hdfs/web/TestWebHdfsFileSystemContract.java b/src/test/org/apache/hadoop/hdfs/web/TestWebHdfsFileSystemContract.java
index ec73833..9728c5c 100644
--- a/src/test/org/apache/hadoop/hdfs/web/TestWebHdfsFileSystemContract.java
+++ b/src/test/org/apache/hadoop/hdfs/web/TestWebHdfsFileSystemContract.java
@@ -29,6 +29,7 @@ import java.security.PrivilegedExceptionAction;
 
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.BlockLocation;
+import org.apache.hadoop.fs.FSDataInputStream;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.FileSystemContractBaseTest;
 import org.apache.hadoop.fs.Path;
@@ -179,4 +180,16 @@ public class TestWebHdfsFileSystemContract extends FileSystemContractBaseTest {
     //check if the command successes.
     assertTrue(fs.getFileStatus(p).isDir());
   }
+
+  public void testOpenNonExistFile() throws IOException {
+    final Path p = new Path("/test/testOpenNonExistFile");
+    //open it as a file, should get FileNotFoundException 
+    try {
+      final FSDataInputStream in = fs.open(p);
+      in.read();
+      fail();
+    } catch(FileNotFoundException fnfe) {
+      WebHdfsFileSystem.LOG.info("This is expected.", fnfe);
+    }
+  }
 }
-- 
1.7.0.4

